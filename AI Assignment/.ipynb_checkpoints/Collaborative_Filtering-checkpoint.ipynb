{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd27403-0056-40f0-8f55-1ac57b1d082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id   book_id  \\\n",
      "0  8842281e1d1347389f2ab93d60773d4d  10893214   \n",
      "1  8842281e1d1347389f2ab93d60773d4d  33282947   \n",
      "2  8842281e1d1347389f2ab93d60773d4d  11387515   \n",
      "3  8842281e1d1347389f2ab93d60773d4d  24396144   \n",
      "4  8842281e1d1347389f2ab93d60773d4d  20484662   \n",
      "\n",
      "                          review_id  is_read  rating review_text_incomplete  \\\n",
      "0  5d0e4e8825c68740703f65a18813fc93    False       0                    NaN   \n",
      "1  f171a68daa8092d8aea3dccc2e025a81    False       0                    NaN   \n",
      "2  2fd3cd1acb30b099c135e358669639da    False       0                    NaN   \n",
      "3  d210e41fcc7e6dcd6ae896844a38a024    False       0                    NaN   \n",
      "4  a99f9fa4ec4fd94cc2419c78af2086a8    False       0                    NaN   \n",
      "\n",
      "                       date_added                    date_updated read_at  \\\n",
      "0  Fri Feb 24 09:00:30 -0800 2017  Fri Feb 24 09:00:30 -0800 2017     NaN   \n",
      "1  Fri Feb 10 10:47:53 -0800 2017  Fri Feb 10 10:48:21 -0800 2017     NaN   \n",
      "2  Thu Jan 26 13:35:10 -0800 2017  Thu Jan 26 13:35:10 -0800 2017     NaN   \n",
      "3  Thu Dec 15 15:37:54 -0800 2016  Thu Dec 15 15:37:55 -0800 2016     NaN   \n",
      "4  Sun May 15 14:49:50 -0700 2016  Sun May 15 14:49:51 -0700 2016     NaN   \n",
      "\n",
      "  started_at  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interaction_df = pd.read_csv(\"C:/Users/minge/Downloads/csv file/interactions_data_file.csv\")\n",
    "\n",
    "print(interaction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50177cc5-f261-45ee-89f9-50c219d9a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                   object\n",
      "book_id                    int64\n",
      "review_id                 object\n",
      "is_read                     bool\n",
      "rating                     int64\n",
      "review_text_incomplete    object\n",
      "date_added                object\n",
      "date_updated              object\n",
      "read_at                   object\n",
      "started_at                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(interaction_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce1baee-1f48-484a-90d2-4342e2f0d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "interaction_df['rating'] = pd.to_numeric(interaction_df['rating'], errors='coerce')\n",
    "required_columns = ['user_id', 'book_id', 'rating']\n",
    "df_preprocessed = (interaction_df[required_columns]\n",
    "                  .drop_duplicates()\n",
    "                  .dropna()\n",
    "                  .query(\"rating >= 3.5\"))\n",
    "\n",
    "# filter to top active users/books\n",
    "top_users = df_preprocessed['user_id'].value_counts().head(20000).index\n",
    "top_books = df_preprocessed['book_id'].value_counts().head(20000).index\n",
    "filtered_df = df_preprocessed[\n",
    "    df_preprocessed['user_id'].isin(top_users) & \n",
    "    df_preprocessed['book_id'].isin(top_books)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780ee692-8509-4360-be8a-57da93503465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing:\n",
      "Unique users: 430848\n",
      "Unique books: 112365\n",
      "Total ratings: 4573179\n"
     ]
    }
   ],
   "source": [
    "print(\"After preprocessing:\")\n",
    "print(\"Unique users:\", df_preprocessed['user_id'].nunique())\n",
    "print(\"Unique books:\", df_preprocessed['book_id'].nunique())\n",
    "print(\"Total ratings:\", len(df_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce78b589-43e1-4133-8247-14412b4a95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create mappings\n",
    "user_to_idx = {user: idx for idx, user in enumerate(filtered_df['user_id'].unique())}\n",
    "book_to_idx = {book: idx for idx, book in enumerate(filtered_df['book_id'].unique())}\n",
    "\n",
    "# Create sparse matrix\n",
    "rows = filtered_df['user_id'].map(user_to_idx)\n",
    "cols = filtered_df['book_id'].map(book_to_idx)\n",
    "values = filtered_df['rating']\n",
    "\n",
    "sparse_matrix = csr_matrix((values, (rows, cols)), \n",
    "                        shape=(len(user_to_idx), len(book_to_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bb0137-7d27-4865-86ae-89f0317986f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c8042a-c503-4f59-976b-baa22e75f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process pivot table in batches for Users and Items\n",
    "batch_size = 5000\n",
    "dense_chunks = []\n",
    "\n",
    "for i in range(0, 20000, batch_size):\n",
    "    # Get batch of users\n",
    "    batch_users = list(user_to_idx.keys())[i:i+batch_size]\n",
    "    batch_df = filtered_df[filtered_df['user_id'].isin(batch_users)]\n",
    "    \n",
    "    # Create dense batch matrix\n",
    "    batch_matrix = batch_df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='book_id',\n",
    "        values='rating',\n",
    "        fill_value=0\n",
    "    ).reindex(index=batch_users, columns=book_to_idx.keys(), fill_value=0)\n",
    "    \n",
    "    dense_chunks.append(batch_matrix)\n",
    "\n",
    "# Combine to final pivot table\n",
    "user_item_matrix = pd.concat(dense_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7d20a9-e767-448b-a835-5c1eecd5771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>23310161</th>\n",
       "      <th>817720</th>\n",
       "      <th>502362</th>\n",
       "      <th>1969280</th>\n",
       "      <th>17290220</th>\n",
       "      <th>1027760</th>\n",
       "      <th>231850</th>\n",
       "      <th>460548</th>\n",
       "      <th>4948</th>\n",
       "      <th>76933</th>\n",
       "      <th>...</th>\n",
       "      <th>9675860</th>\n",
       "      <th>17927219</th>\n",
       "      <th>13139295</th>\n",
       "      <th>26213166</th>\n",
       "      <th>10266194</th>\n",
       "      <th>10531351</th>\n",
       "      <th>10772394</th>\n",
       "      <th>8456290</th>\n",
       "      <th>7574926</th>\n",
       "      <th>15942760</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8842281e1d1347389f2ab93d60773d4d</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b2e5fe9fd353fecf3eeebb4850b88d3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672eb229c808b792b8ea95f01f19784</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559d843b319087e12f48282e386e401f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cd6522e9018f2f77332ec74f928f8c45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edb4e5298a821ecdcf49b49e99a9848a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b9260c7c314956d4dd9be954adbb932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df61fb0b19aa2c1c277b1deb8e575824</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d509e8da95c233acac0753b8783d426a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e164263df221cc444dab1c406e0ccb87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 19810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id                           23310161  817720    502362    1969280   \\\n",
       "user_id                                                                    \n",
       "8842281e1d1347389f2ab93d60773d4d       4.0       5.0       5.0       5.0   \n",
       "7b2e5fe9fd353fecf3eeebb4850b88d3       0.0       0.0       0.0       0.0   \n",
       "4672eb229c808b792b8ea95f01f19784       0.0       0.0       0.0       0.0   \n",
       "559d843b319087e12f48282e386e401f       0.0       0.0       0.0       0.0   \n",
       "cd6522e9018f2f77332ec74f928f8c45       0.0       0.0       0.0       0.0   \n",
       "...                                    ...       ...       ...       ...   \n",
       "edb4e5298a821ecdcf49b49e99a9848a       0.0       0.0       0.0       0.0   \n",
       "0b9260c7c314956d4dd9be954adbb932       0.0       0.0       0.0       0.0   \n",
       "df61fb0b19aa2c1c277b1deb8e575824       0.0       0.0       0.0       0.0   \n",
       "d509e8da95c233acac0753b8783d426a       0.0       0.0       0.0       0.0   \n",
       "e164263df221cc444dab1c406e0ccb87       0.0       0.0       0.0       0.0   \n",
       "\n",
       "book_id                           17290220  1027760   231850    460548    \\\n",
       "user_id                                                                    \n",
       "8842281e1d1347389f2ab93d60773d4d       5.0       4.0       5.0       5.0   \n",
       "7b2e5fe9fd353fecf3eeebb4850b88d3       0.0       0.0       0.0       0.0   \n",
       "4672eb229c808b792b8ea95f01f19784       0.0       0.0       0.0       0.0   \n",
       "559d843b319087e12f48282e386e401f       0.0       0.0       0.0       0.0   \n",
       "cd6522e9018f2f77332ec74f928f8c45       0.0       0.0       0.0       0.0   \n",
       "...                                    ...       ...       ...       ...   \n",
       "edb4e5298a821ecdcf49b49e99a9848a       0.0       0.0       4.0       0.0   \n",
       "0b9260c7c314956d4dd9be954adbb932       0.0       0.0       0.0       0.0   \n",
       "df61fb0b19aa2c1c277b1deb8e575824       0.0       0.0       5.0       5.0   \n",
       "d509e8da95c233acac0753b8783d426a       0.0       0.0       0.0       0.0   \n",
       "e164263df221cc444dab1c406e0ccb87       0.0       0.0       5.0       0.0   \n",
       "\n",
       "book_id                           4948      76933     ...  9675860   17927219  \\\n",
       "user_id                                               ...                       \n",
       "8842281e1d1347389f2ab93d60773d4d       5.0       5.0  ...       0.0       0.0   \n",
       "7b2e5fe9fd353fecf3eeebb4850b88d3       0.0       0.0  ...       0.0       0.0   \n",
       "4672eb229c808b792b8ea95f01f19784       0.0       0.0  ...       0.0       0.0   \n",
       "559d843b319087e12f48282e386e401f       0.0       0.0  ...       0.0       0.0   \n",
       "cd6522e9018f2f77332ec74f928f8c45       0.0       0.0  ...       0.0       0.0   \n",
       "...                                    ...       ...  ...       ...       ...   \n",
       "edb4e5298a821ecdcf49b49e99a9848a       0.0       0.0  ...       0.0       0.0   \n",
       "0b9260c7c314956d4dd9be954adbb932       0.0       0.0  ...       0.0       0.0   \n",
       "df61fb0b19aa2c1c277b1deb8e575824       0.0       0.0  ...       0.0       0.0   \n",
       "d509e8da95c233acac0753b8783d426a       0.0       0.0  ...       0.0       0.0   \n",
       "e164263df221cc444dab1c406e0ccb87       0.0       0.0  ...       0.0       0.0   \n",
       "\n",
       "book_id                           13139295  26213166  10266194  10531351  \\\n",
       "user_id                                                                    \n",
       "8842281e1d1347389f2ab93d60773d4d       0.0       0.0       0.0       0.0   \n",
       "7b2e5fe9fd353fecf3eeebb4850b88d3       0.0       0.0       0.0       0.0   \n",
       "4672eb229c808b792b8ea95f01f19784       0.0       0.0       0.0       0.0   \n",
       "559d843b319087e12f48282e386e401f       0.0       0.0       0.0       0.0   \n",
       "cd6522e9018f2f77332ec74f928f8c45       0.0       0.0       0.0       0.0   \n",
       "...                                    ...       ...       ...       ...   \n",
       "edb4e5298a821ecdcf49b49e99a9848a       0.0       0.0       0.0       0.0   \n",
       "0b9260c7c314956d4dd9be954adbb932       0.0       0.0       0.0       0.0   \n",
       "df61fb0b19aa2c1c277b1deb8e575824       0.0       0.0       0.0       0.0   \n",
       "d509e8da95c233acac0753b8783d426a       0.0       0.0       0.0       0.0   \n",
       "e164263df221cc444dab1c406e0ccb87       0.0       0.0       0.0       0.0   \n",
       "\n",
       "book_id                           10772394  8456290   7574926   15942760  \n",
       "user_id                                                                   \n",
       "8842281e1d1347389f2ab93d60773d4d       0.0       0.0       0.0       0.0  \n",
       "7b2e5fe9fd353fecf3eeebb4850b88d3       0.0       0.0       0.0       0.0  \n",
       "4672eb229c808b792b8ea95f01f19784       0.0       0.0       0.0       0.0  \n",
       "559d843b319087e12f48282e386e401f       0.0       0.0       0.0       0.0  \n",
       "cd6522e9018f2f77332ec74f928f8c45       0.0       0.0       0.0       0.0  \n",
       "...                                    ...       ...       ...       ...  \n",
       "edb4e5298a821ecdcf49b49e99a9848a       0.0       0.0       0.0       0.0  \n",
       "0b9260c7c314956d4dd9be954adbb932       0.0       0.0       0.0       0.0  \n",
       "df61fb0b19aa2c1c277b1deb8e575824       0.0       0.0       0.0       0.0  \n",
       "d509e8da95c233acac0753b8783d426a       0.0       0.0       0.0       0.0  \n",
       "e164263df221cc444dab1c406e0ccb87       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[20000 rows x 19810 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe6991-8125-458d-8a08-0f32c70798df",
   "metadata": {},
   "source": [
    "Memory-based collaborative filtering\n",
    "1. User-based filtering\n",
    "2. Item-based filtering\n",
    "\n",
    "mean: The average rating given to the book by the similar users.\n",
    "\n",
    "count: The number of similar users who rated that book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68af60-0549-4cbe-becb-e4a04973263b",
   "metadata": {},
   "source": [
    "1. User-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d0fd7d-ef30-4b2f-99df-75301cc46222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def get_top_similar_users_knn(target_user_id, user_item_df, n=5):\n",
    "    user_ids = user_item_df.index\n",
    "    # Convert to sparse \n",
    "    user_item_matrix = csr_matrix(user_item_df.values)\n",
    "\n",
    "    # Find similar users\n",
    "    knn = NearestNeighbors(n_neighbors=n+1, metric='cosine', algorithm='brute')\n",
    "    knn.fit(user_item_matrix)\n",
    "    \n",
    "    # target_idx = user_item_matrix.index.get_loc(target_user_id)\n",
    "    target_idx = user_ids.get_loc(target_user_id)\n",
    "    distances, indices = knn.kneighbors(user_item_matrix[target_idx])\n",
    "    \n",
    "    # Return similar users (excluding the target user themselves)\n",
    "    similar_users = user_ids[indices.flatten()[1:]]\n",
    "    similarities = 1 - distances.flatten()[1:]  # Convert distances to similarities\n",
    "    return pd.Series(similarities, index=similar_users)\n",
    "\n",
    "\"\"\"Get book recommendations from similar users\"\"\"\n",
    "def memory_based_recommendations(target_user_id, user_item_matrix, filtered_df, n_users=5, n_books=5):\n",
    "   \n",
    "    # Get similar users\n",
    "    similar_users = get_top_similar_users_knn(target_user_id, user_item_matrix, n_users)\n",
    "    \n",
    "    # Get books rated by similar users but not by target user\n",
    "    target_books = set(filtered_df[filtered_df['user_id'] == target_user_id]['book_id'])\n",
    "    similar_users_books = filtered_df[filtered_df['user_id'].isin(similar_users.index)]\n",
    "    \n",
    "    # Filter out books already rated by target user\n",
    "    candidate_books = similar_users_books[~similar_users_books['book_id'].isin(target_books)]\n",
    "    \n",
    "    # Calculate weighted ratings based on user similarity\n",
    "    candidate_books = candidate_books.copy()\n",
    "    candidate_books['weighted_rating'] = candidate_books.apply(\n",
    "        lambda x: x['rating'] * similar_users[x['user_id']], axis=1\n",
    "    )\n",
    "    \n",
    "    # Get top rated books with weighted average\n",
    "    book_scores = candidate_books.groupby('book_id').agg({\n",
    "        'weighted_rating': 'sum',\n",
    "        'user_id': 'count',\n",
    "        'rating': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Normalize the weighted ratings by dividing by sum of similarities\n",
    "    book_scores['similarity_sum'] = book_scores['user_id'].apply(\n",
    "        lambda count: sum([similar_users[user] for user in \n",
    "                          candidate_books[candidate_books['book_id'] == book_scores.index[book_scores['user_id'] == count].values[0]]['user_id']])\n",
    "    )\n",
    "    \n",
    "    book_scores['normalized_score'] = book_scores['weighted_rating'] / book_scores['similarity_sum']\n",
    "    \n",
    "    # Sort and get top books\n",
    "    top_books = book_scores.sort_values('normalized_score', ascending=False).head(n_books)\n",
    "    top_books = top_books.reset_index()\n",
    "    \n",
    "    # Merge with book titles\n",
    "    top_books_with_titles = pd.merge(top_books, books_df[['book_id', 'title']], on='book_id', how='left')\n",
    "    \n",
    "    return top_books_with_titles[['book_id', 'title', 'normalized_score', 'rating', 'user_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd8c0f-813e-4548-afec-531313175d9c",
   "metadata": {},
   "source": [
    "2. Item-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d945d901-bec5-4684-b995-d019bb4bc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\"\"\"Compute pairwise item similarities using cosine distance.\"\"\"\n",
    "def get_item_similarities(item_item_matrix, n_neighbors=10, batch_size=1000):\n",
    "    n_items = item_item_matrix.shape[0]\n",
    "    \n",
    "    all_similarities = []\n",
    "    all_indices = []\n",
    "    \n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors+1, metric='cosine', algorithm='brute')\n",
    "    knn.fit(item_item_matrix)\n",
    "\n",
    "    for start in range(0, n_items, batch_size):\n",
    "        end = min(start + batch_size, n_items)\n",
    "        batch = item_item_matrix[start:end]\n",
    "\n",
    "        distances, indices = knn.kneighbors(batch)\n",
    "        similarities = 1 - distances\n",
    "\n",
    "        all_similarities.append(similarities)\n",
    "        all_indices.append(indices)\n",
    "    \n",
    "    # Combine\n",
    "    full_similarities = np.vstack(all_similarities)\n",
    "    full_indices = np.vstack(all_indices)\n",
    "\n",
    "    return full_similarities, full_indices\n",
    "\n",
    "\n",
    "\"\"\"Generate recommendations based on item-item similarities.\"\"\"\n",
    "def item_based_recommendations(target_user_id, user_item_matrix, filtered_df, books_df, n_books=5):\n",
    "    # Get books rated by the target user\n",
    "    target_books = filtered_df[filtered_df['user_id'] == target_user_id]['book_id'].values\n",
    "    \n",
    "    if len(target_books) == 0:\n",
    "        return pd.DataFrame()  # Handle cold-start\n",
    "\n",
    "    # Create item-item matrix (transpose of user-item matrix)\n",
    "    item_item_matrix = user_item_matrix.T \n",
    "    \n",
    "    # Compute item similarities (precompute once and cache for production)\n",
    "    item_similarities, item_indices = get_item_similarities(item_item_matrix)\n",
    "    \n",
    "    # Map book_id to matrix index\n",
    "    book_to_idx = {book_id: idx for idx, book_id in enumerate(user_item_matrix.columns)}\n",
    "    \n",
    "    # For each book rated by the user, find similar books\n",
    "    candidate_scores = defaultdict(float)\n",
    "    for book_id in target_books:\n",
    "        if book_id not in book_to_idx:\n",
    "            continue\n",
    "        book_idx = book_to_idx[book_id]\n",
    "        similar_indices = item_indices[book_idx][1:]  # Exclude self\n",
    "        similar_scores = item_similarities[book_idx][1:]\n",
    "        \n",
    "        # Aggregate scores across all similar items\n",
    "        for sim_idx, sim_score in zip(similar_indices, similar_scores):\n",
    "            similar_book_id = user_item_matrix.columns[sim_idx]\n",
    "            candidate_scores[similar_book_id] += sim_score\n",
    "    \n",
    "    # Filter out books already rated by the user\n",
    "    candidate_scores = {\n",
    "        book_id: score for book_id, score in candidate_scores.items()\n",
    "        if book_id not in target_books\n",
    "    }\n",
    "    \n",
    "    # Sort and get top books\n",
    "    top_books = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:n_books]\n",
    "    top_books = pd.DataFrame(top_books, columns=['book_id', 'item_score'])\n",
    "    \n",
    "    # Merge with book titles\n",
    "    top_books = pd.merge(top_books, books_df[['book_id', 'title']], on='book_id', how='left')\n",
    "    return top_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70335f2-5014-4583-94e7-0d94895e9edb",
   "metadata": {},
   "source": [
    "Train SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6badc8da-c9a4-4f8d-bc2e-997d1b7e3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train SVD model on user-item matrix\"\"\"\n",
    "def train_svd_model(sparse_matrix, n_factors=50):\n",
    "    \n",
    "    # Compute row means efficiently on sparse matrix\n",
    "    row_sums = sparse_matrix.sum(axis=1).A1  # Convert to 1D array\n",
    "    row_counts = np.diff(sparse_matrix.indptr)  # Number of non-zero elements per row\n",
    "    row_means = np.zeros_like(row_sums, dtype=np.float64)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    non_zero_mask = row_counts > 0\n",
    "    row_means[non_zero_mask] = row_sums[non_zero_mask] / row_counts[non_zero_mask]\n",
    "    \n",
    "    # Perform SVD directly on sparse matrix\n",
    "    u, sigma, vt = svds(sparse_matrix, k=50)\n",
    "    \n",
    "    # Convert sigma to diagonal matrix\n",
    "    sigma_diag = np.diag(sigma)\n",
    "    \n",
    "    return (u, sigma, vt, row_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa437d4-a58a-4068-89e9-cfe7a297d58a",
   "metadata": {},
   "source": [
    "Model-based collaborative filtering - SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91784c40-e309-4f9f-8df7-cc95f07c9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get book recommendations using SVD \"\"\"\n",
    "def model_based_recommendations(target_user_id, user_item_matrix, books_df, svd_data, n_books=5):\n",
    "    # Find target user's index\n",
    "    target_idx = user_item_matrix.index.get_loc(target_user_id)\n",
    "    \n",
    "    # Unpack SVD data\n",
    "    u, sigma, vt, user_ratings_mean = svd_data\n",
    "\n",
    "    # Build book_to_idx dictionary here\n",
    "    book_to_idx = {book_id: idx for idx, book_id in enumerate(user_item_matrix.columns)}\n",
    "\n",
    "    # Reconstruct the ratings for the target user only (not the whole matrix)\n",
    "    user_u = u[target_idx].reshape(1, -1)\n",
    "    user_predicted = user_ratings_mean[target_idx] + np.dot(np.dot(user_u, np.diag(sigma)), vt)\n",
    "    user_predicted = user_predicted.flatten()\n",
    "    \n",
    "    # Get books that user hasn't rated\n",
    "    user_rated_books = user_item_matrix.loc[target_user_id]\n",
    "    user_rated_indices = user_rated_books[user_rated_books > 0].index\n",
    "    rated_indices = [book_to_idx[book] for book in user_rated_indices if book in book_to_idx]\n",
    "    \n",
    "    # Create mask for unrated items (1 for unrated, 0 for rated)\n",
    "    mask = np.ones(len(book_to_idx), dtype=bool)\n",
    "    mask[rated_indices] = False\n",
    "    \n",
    "    # Apply mask to get only predictions for unrated items\n",
    "    unrated_predictions = user_predicted[mask]\n",
    "    unrated_indices = np.arange(len(book_to_idx))[mask]\n",
    "    \n",
    "    # Get top n books based on predictions\n",
    "    top_indices = unrated_predictions.argsort()[-n_books:][::-1]\n",
    "    top_book_indices = unrated_indices[top_indices]\n",
    "    top_predictions = unrated_predictions[top_indices]\n",
    "    \n",
    "    # Convert indices back to book_ids\n",
    "    idx_to_book = {idx: book_id for book_id, idx in book_to_idx.items()}\n",
    "    top_book_ids = [idx_to_book[idx] for idx in top_book_indices]\n",
    "    \n",
    "    # Create dataframe with results\n",
    "    results = pd.DataFrame({\n",
    "        'book_id': top_book_ids,\n",
    "        'predicted_rating': top_predictions\n",
    "    })\n",
    "    \n",
    "    # Merge with book titles\n",
    "    results = pd.merge(results, books_df[['book_id', 'title']], on='book_id', how='left')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16addc42-f507-4e80-bc7a-6130d03cd59b",
   "metadata": {},
   "source": [
    "Collaborative Filtering\n",
    "- Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33f998e7-ebfd-40f8-b538-05cb8499b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get book recommendations using a hybrid approach\"\"\"\n",
    "def collaborative_recommendations(target_user_id, user_item_matrix, filtered_df, books_df, \n",
    "                          svd_data, alpha=0.4, beta=0.3, gamma=0.3, n_users=5, n_books=10):\n",
    "    \"\"\"\n",
    "    Combine user-based, item-based, and model-based recommendations.\n",
    "    Weights:\n",
    "    - alpha: user-based\n",
    "    - beta: item-based\n",
    "    - gamma: model-based (alpha + beta + gamma = 1)\n",
    "    \"\"\"\n",
    "    # Get recommendations from all three methods\n",
    "    user_recs = memory_based_recommendations(target_user_id, user_item_matrix, filtered_df, n_users, n_books*3)\n",
    "    item_recs = item_based_recommendations(target_user_id, user_item_matrix, filtered_df, books_df, n_books*3)\n",
    "    model_recs = model_based_recommendations(target_user_id, user_item_matrix, books_df, svd_data, n_books*3)\n",
    "    \n",
    "    # Normalize scores to [0, 1] for fair comparison\n",
    "    def normalize_scores(df, score_col):\n",
    "        min_score = df[score_col].min()\n",
    "        max_score = df[score_col].max()\n",
    "        df[score_col] = (df[score_col] - min_score) / (max_score - min_score + 1e-10)\n",
    "        return df\n",
    "    \n",
    "    user_recs = normalize_scores(user_recs, 'normalized_score')\n",
    "    item_recs = normalize_scores(item_recs, 'item_score')\n",
    "    model_recs = normalize_scores(model_recs, 'predicted_rating')\n",
    "    \n",
    "    # Create dictionaries for easy lookup\n",
    "    user_scores = dict(zip(user_recs['book_id'], user_recs['normalized_score']))\n",
    "    item_scores = dict(zip(item_recs['book_id'], item_recs['item_score']))\n",
    "    model_scores = dict(zip(model_recs['book_id'], model_recs['predicted_rating']))\n",
    "    \n",
    "    # Combine scores from all methods\n",
    "    all_books = set(user_scores.keys()) | set(item_scores.keys()) | set(model_scores.keys())\n",
    "    hybrid_scores = {}\n",
    "    \n",
    "    for book_id in all_books:\n",
    "        hybrid_scores[book_id] = (\n",
    "            alpha * user_scores.get(book_id, 0) +\n",
    "            beta * item_scores.get(book_id, 0) +\n",
    "            gamma * model_scores.get(book_id, 0)\n",
    "        )\n",
    "    \n",
    "    # Sort and return top books\n",
    "    top_books = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)[:n_books]\n",
    "    results = pd.DataFrame(top_books, columns=['book_id', 'hybrid_score'])\n",
    "    \n",
    "    # Add component scores for debugging/analysis\n",
    "    results['user_score'] = results['book_id'].map(user_scores).fillna(0)\n",
    "    results['item_score'] = results['book_id'].map(item_scores).fillna(0)\n",
    "    results['model_score'] = results['book_id'].map(model_scores).fillna(0)\n",
    "    \n",
    "    # Merge with book titles\n",
    "    results = pd.merge(results, books_df[['book_id', 'title']], on='book_id', how='left')\n",
    "    results.rename(columns={'user_score': 'memory_score'}, inplace=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77736542-95e8-4d42-a781-b4f37c4cae06",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7040e568-3a6e-4cb0-830d-f33614317e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Book Recommendation System ===\n",
      "This system uses **User-based collaborative filtering** to recommend books.\n",
      "Training SVD model...\n",
      "SVD model trained successfully!\n",
      "\n",
      "Available user IDs: ['8842281e1d1347389f2ab93d60773d4d', '7b2e5fe9fd353fecf3eeebb4850b88d3', '4672eb229c808b792b8ea95f01f19784', '559d843b319087e12f48282e386e401f', 'cd6522e9018f2f77332ec74f928f8c45'] ... (and more)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter user ID to get book recommendations (Q to quit):  8842281e1d1347389f2ab93d60773d4d\n",
      "How many similar users to consider? (Default 5):  5\n",
      "How many book recommendations? (Default 5):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 book recommendations for user 8842281e1d1347389f2ab93d60773d4d (collaborative):\n",
      "                title  hybrid_score  memory_score  model_score\n",
      "0   A Little Princess      0.453105      1.000000     0.177018\n",
      "1      Goodnight Moon      0.399786      0.000000     1.000000\n",
      "2     Charlotte's Web      0.397176      0.000000     0.323920\n",
      "3  The Cat in the Hat      0.328177      0.000000     0.644413\n",
      "4        Black Beauty      0.234429      0.384355     0.268958\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Find more recommendations? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Program ended.\n"
     ]
    }
   ],
   "source": [
    "books_df = pd.read_csv(\"C:/Users/minge/Downloads/csv file/books_data_file.csv\")\n",
    "print(\"\\n=== Book Recommendation System ===\")\n",
    "print(\"This system uses **User-based collaborative filtering** to recommend books.\")\n",
    "\n",
    "# Train SVD model (always used in hybrid)\n",
    "print(\"Training SVD model...\")\n",
    "sparse_mat = csr_matrix(user_item_matrix.values)\n",
    "try:\n",
    "    svd_data = train_svd_model(sparse_mat, n_factors=20)\n",
    "    print(\"SVD model trained successfully!\")\n",
    "except MemoryError:\n",
    "    print(\"Error: Not enough memory for SVD model. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    print(\"\\nAvailable user IDs:\", list(user_item_matrix.index)[:5], \"... (and more)\")\n",
    "    target_user = input(\"Enter user ID to get book recommendations (Q to quit): \").strip()\n",
    "    \n",
    "    if target_user.lower() == 'q':\n",
    "        break\n",
    "\n",
    "    if target_user not in user_item_matrix.index:\n",
    "        print(f\"Error: User '{target_user}' not found\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        n_users = int(input(\"How many similar users to consider? (Default 5): \") or 5)\n",
    "        n_books = int(input(\"How many book recommendations? (Default 5): \") or 5)\n",
    "        \n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Using default values.\")\n",
    "        n_users, n_books, alpha = 5, 5, 0.5\n",
    "\n",
    "    recommendations = collaborative_recommendations(\n",
    "        target_user, user_item_matrix, filtered_df, books_df, \n",
    "        svd_data, n_users=n_users, n_books=n_books\n",
    "    )\n",
    "    print(f\"\\nTop {n_books} book recommendations for user {target_user} (collaborative):\")\n",
    "    print(recommendations[['title', 'hybrid_score', 'memory_score', 'model_score']])\n",
    "\n",
    "    if input(\"\\nFind more recommendations? (y/n): \").lower() != 'y':\n",
    "        break\n",
    "\n",
    "print(\"\\nProgram ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60c1d5-9238-4d50-91d6-e6af2dce6f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
