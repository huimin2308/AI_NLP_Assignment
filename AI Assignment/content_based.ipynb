{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daea6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully, rows: 77168\n",
      "Rows after preprocessing: 76542\n",
      "Content column sample: 0    zap!_i'm_a_mind_reader whod thought mind readi...\n",
      "1    the_original_adventures_of_hank_the_cowdog_(ha...\n",
      "Name: content, dtype: object\n",
      "TF-IDF matrix shape: (76542, 500)\n",
      "TF-IDF matrix memory usage: 9.25 MB\n",
      "NearestNeighbors model fitted successfully\n",
      "Indices sample: title\n",
      "zap!_i'm_a_mind_reader                                              0\n",
      "the_original_adventures_of_hank_the_cowdog_(hank_the_cowdog,_#1)    1\n",
      "lara_and_the_gray_mare_(hoofbeats:_lara_and_the_gray_mare,_#1)      2\n",
      "the_gunny_sack_man                                                  3\n",
      "gobbolino,_the_witch's_cat                                          4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_books_data.xls')\n",
    "    print(f\"Dataset loaded successfully, rows: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'books_data_file.csv' not found, please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['title', 'description']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    print(f\"Error: Dataset missing columns: {[col for col in required_columns if col not in df.columns]}\")\n",
    "    exit()\n",
    "\n",
    "# Select columns and preprocess\n",
    "df = df[required_columns].drop_duplicates().dropna()\n",
    "\n",
    "print(f\"Rows after preprocessing: {len(df)}\")\n",
    "\n",
    "# Combine title and description\n",
    "df['content'] = df['title'] + ' ' + df['description']\n",
    "print(f\"Content column sample: {df['content'].head(2)}\")\n",
    "\n",
    "# Build TF-IDF model\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500, min_df=5)\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"TF-IDF matrix memory usage: {tfidf_matrix.data.nbytes / 1e6:.2f} MB\")\n",
    "\n",
    "# Build NearestNeighbors model\n",
    "nn = NearestNeighbors(n_neighbors=11, metric='cosine', algorithm='brute', n_jobs=-1)  # 11 to account for self\n",
    "nn.fit(tfidf_matrix)\n",
    "print(\"NearestNeighbors model fitted successfully\")\n",
    "\n",
    "# Create title-to-index mapping\n",
    "indices = pd.Series(df.index, index=df['title']).drop_duplicates(keep='first')\n",
    "print(f\"Indices sample: {indices.head()}\")\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_books(title, nn_model=nn, top_n=10):\n",
    "    print(f\"Recommending for title: {title}\")\n",
    "    \n",
    "    # Check if title exists\n",
    "    if title not in indices:\n",
    "        print(f\"Title '{title}' not in dataset.\")\n",
    "        return None\n",
    "    \n",
    "    # Get index\n",
    "    idx = indices[title]\n",
    "    print(f\"Index for title '{title}': {idx}\")\n",
    "    \n",
    "    # Ensure idx is an integer\n",
    "    if isinstance(idx, (int, np.integer)):\n",
    "        idx = idx\n",
    "    else:\n",
    "        idx = idx[0]  # Take first if multiple\n",
    "    \n",
    "    # Get nearest neighbors\n",
    "    distances, book_indices = nn_model.kneighbors(tfidf_matrix[idx], n_neighbors=top_n + 1)\n",
    "    book_indices = book_indices.flatten()[1:]  # Exclude self\n",
    "    distances = distances.flatten()[1:]  # Exclude self\n",
    "    similarities = 1 - distances  # Convert distance to similarity\n",
    "    \n",
    "    print(f\"Recommended book indices: {book_indices}\")\n",
    "    print(f\"Similarity scores sample: {similarities[:5]}\")\n",
    "    \n",
    "    # Return results\n",
    "    result = df.iloc[book_indices][['title','description']].copy()\n",
    "    result['similarity_score'] = similarities\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "458d2e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending for title: zap!_i'm_a_mind_reader\n",
      "Index for title 'zap!_i'm_a_mind_reader': 0\n",
      "Recommended book indices: [22949 47780 23053  9420 57186 37470 53139 40052 53460 68972]\n",
      "Similarity scores sample: [0.61824968 0.49646353 0.4859334  0.47090507 0.45016153]\n",
      "Recommendation results:\n",
      "                                                  title  \\\n",
      "23037                                      the_castaway   \n",
      "48057                                     the_paw_thing   \n",
      "23141                           the_mean_old_mean_hyena   \n",
      "9450                                     the_silly_book   \n",
      "57528                                    this_is_silly!   \n",
      "37678                             the_big_book_of_silly   \n",
      "53453                                  the_silly_gooses   \n",
      "40278           smelly_locker:_silly_dilly_school_songs   \n",
      "53777         the_mean_and_vulgar_bits._kjartan_poskitt   \n",
      "69404  the_mean_and_vulgar_bits:_fractions_and_averages   \n",
      "\n",
      "                                             description  similarity_score  \n",
      "23037    james stevenson could thought reading believing          0.618250  \n",
      "48057  mac walked safe opened took black book flipped...          0.496464  \n",
      "23141  zebra ostrich elephant lion become hapless vic...          0.485933  \n",
      "9450   stoo hamples classic elicits fresh round giggl...          0.470905  \n",
      "57528  fresh startling picturebook debut gary taxali ...          0.450162  \n",
      "37678  big book silly encompasses silly things make u...          0.449092  \n",
      "53453  upon pond lived silly goose silly geese wanted...          0.434109  \n",
      "40278  uproarious creators take bathtub silly dilly s...          0.420852  \n",
      "53777  maths making miserable frazzled fractions alar...          0.419721  \n",
      "69404  maths making miserable frazzled fractions alar...          0.419721  \n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_books(\"zap!_i'm_a_mind_reader\")\n",
    "if recommendations is None:\n",
    "    print(\"Recommendation result is None, please check debug information.\")\n",
    "else:\n",
    "    print(\"Recommendation results:\")\n",
    "    print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc7ebe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the accuray based on the similarity book\n",
    "# since the result is only return top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b815c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully, rows: 77168\n",
      "Rows after preprocessing: 77168\n",
      "Rows with valid similar_books: 35222\n",
      "Content column sample: 0    zap!_i'm_a_mind_reader whod thought mind readi...\n",
      "1    the_original_adventures_of_hank_the_cowdog_(ha...\n",
      "Name: content, dtype: object\n",
      "TF-IDF matrix shape: (35222, 500)\n",
      "TF-IDF matrix memory usage: 4.44 MB\n",
      "NearestNeighbors model fitted successfully\n",
      "Evaluated 100 books, current mean precision: 0.0000\n",
      "Evaluated 200 books, current mean precision: 0.0000\n",
      "Evaluated 300 books, current mean precision: 0.0000\n",
      "Evaluated 400 books, current mean precision: 0.0000\n",
      "Evaluated 500 books, current mean precision: 0.0000\n",
      "Evaluated 600 books, current mean precision: 0.0000\n",
      "Evaluated 700 books, current mean precision: 0.0000\n",
      "Evaluated 800 books, current mean precision: 0.0000\n",
      "Evaluated 900 books, current mean precision: 0.0000\n",
      "Evaluated 1000 books, current mean precision: 0.0000\n",
      "Evaluated 1100 books, current mean precision: 0.0000\n",
      "Evaluated 1200 books, current mean precision: 0.0000\n",
      "Evaluated 1300 books, current mean precision: 0.0000\n",
      "Evaluated 1400 books, current mean precision: 0.0000\n",
      "Evaluated 1500 books, current mean precision: 0.0000\n",
      "Evaluated 1600 books, current mean precision: 0.0000\n",
      "Evaluated 1700 books, current mean precision: 0.0000\n",
      "Evaluated 1800 books, current mean precision: 0.0000\n",
      "Evaluated 1900 books, current mean precision: 0.0000\n",
      "Evaluated 2000 books, current mean precision: 0.0000\n",
      "Evaluated 2100 books, current mean precision: 0.0000\n",
      "Evaluated 2200 books, current mean precision: 0.0000\n",
      "Evaluated 2300 books, current mean precision: 0.0000\n",
      "Evaluated 2400 books, current mean precision: 0.0000\n",
      "Evaluated 2500 books, current mean precision: 0.0000\n",
      "Evaluated 2600 books, current mean precision: 0.0000\n",
      "Evaluated 2700 books, current mean precision: 0.0000\n",
      "Evaluated 2800 books, current mean precision: 0.0000\n",
      "Evaluated 2900 books, current mean precision: 0.0000\n",
      "Evaluated 3000 books, current mean precision: 0.0000\n",
      "Evaluated 3100 books, current mean precision: 0.0000\n",
      "Evaluated 3200 books, current mean precision: 0.0000\n",
      "Evaluated 3300 books, current mean precision: 0.0000\n",
      "Evaluated 3400 books, current mean precision: 0.0000\n",
      "Evaluated 3500 books, current mean precision: 0.0000\n",
      "Evaluated 3600 books, current mean precision: 0.0000\n",
      "Evaluated 3700 books, current mean precision: 0.0000\n",
      "Evaluated 3800 books, current mean precision: 0.0000\n",
      "Evaluated 3900 books, current mean precision: 0.0000\n",
      "Evaluated 4000 books, current mean precision: 0.0000\n",
      "Evaluated 4100 books, current mean precision: 0.0000\n",
      "Evaluated 4200 books, current mean precision: 0.0000\n",
      "Evaluated 4300 books, current mean precision: 0.0000\n",
      "Evaluated 4400 books, current mean precision: 0.0000\n",
      "Evaluated 4500 books, current mean precision: 0.0000\n",
      "Evaluated 4600 books, current mean precision: 0.0000\n",
      "Evaluated 4700 books, current mean precision: 0.0000\n",
      "Evaluated 4800 books, current mean precision: 0.0000\n",
      "Evaluated 4900 books, current mean precision: 0.0000\n",
      "Evaluated 5000 books, current mean precision: 0.0000\n",
      "Evaluated 5100 books, current mean precision: 0.0000\n",
      "Evaluated 5200 books, current mean precision: 0.0000\n",
      "Evaluated 5300 books, current mean precision: 0.0000\n",
      "Evaluated 5400 books, current mean precision: 0.0000\n",
      "Evaluated 5500 books, current mean precision: 0.0000\n",
      "Evaluated 5600 books, current mean precision: 0.0000\n",
      "Evaluated 5700 books, current mean precision: 0.0000\n",
      "Evaluated 5800 books, current mean precision: 0.0000\n",
      "Evaluated 5900 books, current mean precision: 0.0000\n",
      "Evaluated 6000 books, current mean precision: 0.0000\n",
      "Evaluated 6100 books, current mean precision: 0.0000\n",
      "Evaluated 6200 books, current mean precision: 0.0000\n",
      "Evaluated 6300 books, current mean precision: 0.0000\n",
      "Evaluated 6400 books, current mean precision: 0.0000\n",
      "Evaluated 6500 books, current mean precision: 0.0000\n",
      "Evaluated 6600 books, current mean precision: 0.0000\n",
      "Evaluated 6700 books, current mean precision: 0.0000\n",
      "Evaluated 6800 books, current mean precision: 0.0000\n",
      "Evaluated 6900 books, current mean precision: 0.0000\n",
      "Evaluated 7000 books, current mean precision: 0.0000\n",
      "Evaluated 7100 books, current mean precision: 0.0000\n",
      "Evaluated 7200 books, current mean precision: 0.0000\n",
      "Evaluated 7300 books, current mean precision: 0.0000\n",
      "Evaluated 7400 books, current mean precision: 0.0000\n",
      "Evaluated 7500 books, current mean precision: 0.0000\n",
      "Evaluated 7600 books, current mean precision: 0.0000\n",
      "Evaluated 7700 books, current mean precision: 0.0000\n",
      "Evaluated 7800 books, current mean precision: 0.0000\n",
      "Evaluated 7900 books, current mean precision: 0.0000\n",
      "Evaluated 8000 books, current mean precision: 0.0000\n",
      "Evaluated 8100 books, current mean precision: 0.0000\n",
      "Evaluated 8200 books, current mean precision: 0.0000\n",
      "Evaluated 8300 books, current mean precision: 0.0000\n",
      "Evaluated 8400 books, current mean precision: 0.0000\n",
      "Evaluated 8500 books, current mean precision: 0.0000\n",
      "Evaluated 8600 books, current mean precision: 0.0000\n",
      "Evaluated 8700 books, current mean precision: 0.0000\n",
      "Evaluated 8800 books, current mean precision: 0.0000\n",
      "Evaluated 8900 books, current mean precision: 0.0000\n",
      "Evaluated 9000 books, current mean precision: 0.0000\n",
      "Evaluated 9100 books, current mean precision: 0.0000\n",
      "Evaluated 9200 books, current mean precision: 0.0000\n",
      "Evaluated 9300 books, current mean precision: 0.0000\n",
      "Evaluated 9400 books, current mean precision: 0.0000\n",
      "Evaluated 9500 books, current mean precision: 0.0000\n",
      "Evaluated 9600 books, current mean precision: 0.0000\n",
      "Evaluated 9700 books, current mean precision: 0.0000\n",
      "Evaluated 9800 books, current mean precision: 0.0000\n",
      "Evaluated 9900 books, current mean precision: 0.0000\n",
      "Evaluated 10000 books, current mean precision: 0.0000\n",
      "Evaluated 10100 books, current mean precision: 0.0000\n",
      "Evaluated 10200 books, current mean precision: 0.0000\n",
      "Evaluated 10300 books, current mean precision: 0.0000\n",
      "Evaluated 10400 books, current mean precision: 0.0000\n",
      "Evaluated 10500 books, current mean precision: 0.0000\n",
      "Evaluated 10600 books, current mean precision: 0.0000\n",
      "Evaluated 10700 books, current mean precision: 0.0000\n",
      "Evaluated 10800 books, current mean precision: 0.0000\n",
      "Evaluated 10900 books, current mean precision: 0.0000\n",
      "Evaluated 11000 books, current mean precision: 0.0000\n",
      "Evaluated 11100 books, current mean precision: 0.0000\n",
      "Evaluated 11200 books, current mean precision: 0.0000\n",
      "Evaluated 11300 books, current mean precision: 0.0000\n",
      "Evaluated 11400 books, current mean precision: 0.0000\n",
      "Evaluated 11500 books, current mean precision: 0.0000\n",
      "Evaluated 11600 books, current mean precision: 0.0000\n",
      "Evaluated 11700 books, current mean precision: 0.0000\n",
      "Evaluated 11800 books, current mean precision: 0.0000\n",
      "Evaluated 11900 books, current mean precision: 0.0000\n",
      "Evaluated 12000 books, current mean precision: 0.0000\n",
      "Evaluated 12100 books, current mean precision: 0.0000\n",
      "Evaluated 12200 books, current mean precision: 0.0000\n",
      "Evaluated 12300 books, current mean precision: 0.0000\n",
      "Evaluated 12400 books, current mean precision: 0.0000\n",
      "Evaluated 12500 books, current mean precision: 0.0000\n",
      "Evaluated 12600 books, current mean precision: 0.0000\n",
      "Evaluated 12700 books, current mean precision: 0.0000\n",
      "Evaluated 12800 books, current mean precision: 0.0000\n",
      "Evaluated 12900 books, current mean precision: 0.0000\n",
      "Evaluated 13000 books, current mean precision: 0.0000\n",
      "Evaluated 13100 books, current mean precision: 0.0000\n",
      "Evaluated 13200 books, current mean precision: 0.0000\n",
      "Evaluated 13300 books, current mean precision: 0.0000\n",
      "Evaluated 13400 books, current mean precision: 0.0000\n",
      "Evaluated 13500 books, current mean precision: 0.0000\n",
      "Evaluated 13600 books, current mean precision: 0.0000\n",
      "Evaluated 13700 books, current mean precision: 0.0000\n",
      "Evaluated 13800 books, current mean precision: 0.0000\n",
      "Evaluated 13900 books, current mean precision: 0.0000\n",
      "Evaluated 14000 books, current mean precision: 0.0000\n",
      "Evaluated 14100 books, current mean precision: 0.0000\n",
      "Evaluated 14200 books, current mean precision: 0.0000\n",
      "Evaluated 14300 books, current mean precision: 0.0000\n",
      "Evaluated 14400 books, current mean precision: 0.0000\n",
      "Evaluated 14500 books, current mean precision: 0.0000\n",
      "Evaluated 14600 books, current mean precision: 0.0000\n",
      "Evaluated 14700 books, current mean precision: 0.0000\n",
      "Evaluated 14800 books, current mean precision: 0.0000\n",
      "Evaluated 14900 books, current mean precision: 0.0000\n",
      "Evaluated 15000 books, current mean precision: 0.0000\n",
      "Evaluated 15100 books, current mean precision: 0.0000\n",
      "Evaluated 15200 books, current mean precision: 0.0000\n",
      "Evaluated 15300 books, current mean precision: 0.0000\n",
      "Evaluated 15400 books, current mean precision: 0.0000\n",
      "Evaluated 15500 books, current mean precision: 0.0000\n",
      "Evaluated 15600 books, current mean precision: 0.0000\n",
      "Evaluated 15700 books, current mean precision: 0.0000\n",
      "Evaluated 15800 books, current mean precision: 0.0000\n",
      "Evaluated 15900 books, current mean precision: 0.0000\n",
      "Evaluated 16000 books, current mean precision: 0.0000\n",
      "Evaluated 16100 books, current mean precision: 0.0000\n",
      "Evaluated 16200 books, current mean precision: 0.0000\n",
      "Evaluated 16300 books, current mean precision: 0.0000\n",
      "Evaluated 16400 books, current mean precision: 0.0000\n",
      "Evaluated 16500 books, current mean precision: 0.0000\n",
      "Evaluated 16600 books, current mean precision: 0.0000\n",
      "Evaluated 16700 books, current mean precision: 0.0000\n",
      "Evaluated 16800 books, current mean precision: 0.0000\n",
      "Evaluated 16900 books, current mean precision: 0.0000\n",
      "Evaluated 17000 books, current mean precision: 0.0000\n",
      "Evaluated 17100 books, current mean precision: 0.0000\n",
      "Evaluated 17200 books, current mean precision: 0.0000\n",
      "Evaluated 17300 books, current mean precision: 0.0000\n",
      "Evaluated 17400 books, current mean precision: 0.0000\n",
      "Evaluated 17500 books, current mean precision: 0.0000\n",
      "Evaluated 17600 books, current mean precision: 0.0000\n",
      "Evaluated 17700 books, current mean precision: 0.0000\n",
      "Evaluated 17800 books, current mean precision: 0.0000\n",
      "Evaluated 17900 books, current mean precision: 0.0000\n",
      "Evaluated 18000 books, current mean precision: 0.0000\n",
      "Evaluated 18100 books, current mean precision: 0.0000\n",
      "Evaluated 18200 books, current mean precision: 0.0000\n",
      "Evaluated 18300 books, current mean precision: 0.0000\n",
      "Evaluated 18400 books, current mean precision: 0.0000\n",
      "Evaluated 18500 books, current mean precision: 0.0000\n",
      "Evaluated 18600 books, current mean precision: 0.0000\n",
      "Evaluated 18700 books, current mean precision: 0.0000\n",
      "Evaluated 18800 books, current mean precision: 0.0000\n",
      "Evaluated 18900 books, current mean precision: 0.0000\n",
      "Evaluated 19000 books, current mean precision: 0.0000\n",
      "Evaluated 19100 books, current mean precision: 0.0000\n",
      "Evaluated 19200 books, current mean precision: 0.0000\n",
      "Evaluated 19300 books, current mean precision: 0.0000\n",
      "Evaluated 19400 books, current mean precision: 0.0000\n",
      "Evaluated 19500 books, current mean precision: 0.0000\n",
      "Evaluated 19600 books, current mean precision: 0.0000\n",
      "Evaluated 19700 books, current mean precision: 0.0000\n",
      "Evaluated 19800 books, current mean precision: 0.0000\n",
      "Evaluated 19900 books, current mean precision: 0.0000\n",
      "Evaluated 20000 books, current mean precision: 0.0000\n",
      "Evaluated 20100 books, current mean precision: 0.0000\n",
      "Evaluated 20200 books, current mean precision: 0.0000\n",
      "Evaluated 20300 books, current mean precision: 0.0000\n",
      "Evaluated 20400 books, current mean precision: 0.0000\n",
      "Evaluated 20500 books, current mean precision: 0.0000\n",
      "Evaluated 20600 books, current mean precision: 0.0000\n",
      "Evaluated 20700 books, current mean precision: 0.0000\n",
      "Evaluated 20800 books, current mean precision: 0.0000\n",
      "Evaluated 20900 books, current mean precision: 0.0000\n",
      "Evaluated 21000 books, current mean precision: 0.0000\n",
      "Evaluated 21100 books, current mean precision: 0.0000\n",
      "Evaluated 21200 books, current mean precision: 0.0000\n",
      "Evaluated 21300 books, current mean precision: 0.0000\n",
      "Evaluated 21400 books, current mean precision: 0.0000\n",
      "Evaluated 21500 books, current mean precision: 0.0000\n",
      "Evaluated 21600 books, current mean precision: 0.0000\n",
      "Evaluated 21700 books, current mean precision: 0.0000\n",
      "Evaluated 21800 books, current mean precision: 0.0000\n",
      "Evaluated 21900 books, current mean precision: 0.0000\n",
      "Evaluated 22000 books, current mean precision: 0.0000\n",
      "Evaluated 22100 books, current mean precision: 0.0000\n",
      "Evaluated 22200 books, current mean precision: 0.0000\n",
      "Evaluated 22300 books, current mean precision: 0.0000\n",
      "Evaluated 22400 books, current mean precision: 0.0000\n",
      "Evaluated 22500 books, current mean precision: 0.0000\n",
      "Evaluated 22600 books, current mean precision: 0.0000\n",
      "Evaluated 22700 books, current mean precision: 0.0000\n",
      "Evaluated 22800 books, current mean precision: 0.0000\n",
      "Evaluated 22900 books, current mean precision: 0.0000\n",
      "Evaluated 23000 books, current mean precision: 0.0000\n",
      "Evaluated 23100 books, current mean precision: 0.0000\n",
      "Evaluated 23200 books, current mean precision: 0.0000\n",
      "Evaluated 23300 books, current mean precision: 0.0000\n",
      "Evaluated 23400 books, current mean precision: 0.0000\n",
      "Evaluated 23500 books, current mean precision: 0.0000\n",
      "Evaluated 23600 books, current mean precision: 0.0000\n",
      "Evaluated 23700 books, current mean precision: 0.0000\n",
      "Evaluated 23800 books, current mean precision: 0.0000\n",
      "Evaluated 23900 books, current mean precision: 0.0000\n",
      "Evaluated 24000 books, current mean precision: 0.0000\n",
      "Evaluated 24100 books, current mean precision: 0.0000\n",
      "Evaluated 24200 books, current mean precision: 0.0000\n",
      "Evaluated 24300 books, current mean precision: 0.0000\n",
      "Evaluated 24400 books, current mean precision: 0.0000\n",
      "Evaluated 24500 books, current mean precision: 0.0000\n",
      "Evaluated 24600 books, current mean precision: 0.0000\n",
      "Evaluated 24700 books, current mean precision: 0.0000\n",
      "Evaluated 24800 books, current mean precision: 0.0000\n",
      "Evaluated 24900 books, current mean precision: 0.0000\n",
      "Evaluated 25000 books, current mean precision: 0.0000\n",
      "Evaluated 25100 books, current mean precision: 0.0000\n",
      "Evaluated 25200 books, current mean precision: 0.0000\n",
      "Evaluated 25300 books, current mean precision: 0.0000\n",
      "Evaluated 25400 books, current mean precision: 0.0000\n",
      "Evaluated 25500 books, current mean precision: 0.0000\n",
      "Evaluated 25600 books, current mean precision: 0.0000\n",
      "Evaluated 25700 books, current mean precision: 0.0000\n",
      "Evaluated 25800 books, current mean precision: 0.0000\n",
      "Evaluated 25900 books, current mean precision: 0.0000\n",
      "Evaluated 26000 books, current mean precision: 0.0000\n",
      "Evaluated 26100 books, current mean precision: 0.0000\n",
      "Evaluated 26200 books, current mean precision: 0.0000\n",
      "Evaluated 26300 books, current mean precision: 0.0000\n",
      "Evaluated 26400 books, current mean precision: 0.0000\n",
      "Evaluated 26500 books, current mean precision: 0.0000\n",
      "Evaluated 26600 books, current mean precision: 0.0000\n",
      "Evaluated 26700 books, current mean precision: 0.0000\n",
      "Evaluated 26800 books, current mean precision: 0.0000\n",
      "Evaluated 26900 books, current mean precision: 0.0000\n",
      "Evaluated 27000 books, current mean precision: 0.0000\n",
      "Evaluated 27100 books, current mean precision: 0.0000\n",
      "Evaluated 27200 books, current mean precision: 0.0000\n",
      "Evaluated 27300 books, current mean precision: 0.0000\n",
      "Evaluated 27400 books, current mean precision: 0.0000\n",
      "Evaluated 27500 books, current mean precision: 0.0000\n",
      "Evaluated 27600 books, current mean precision: 0.0000\n",
      "Evaluated 27700 books, current mean precision: 0.0000\n",
      "Evaluated 27800 books, current mean precision: 0.0000\n",
      "Evaluated 27900 books, current mean precision: 0.0000\n",
      "Evaluated 28000 books, current mean precision: 0.0000\n",
      "Evaluated 28100 books, current mean precision: 0.0000\n",
      "Evaluated 28200 books, current mean precision: 0.0000\n",
      "Evaluated 28300 books, current mean precision: 0.0000\n",
      "Evaluated 28400 books, current mean precision: 0.0000\n",
      "Evaluated 28500 books, current mean precision: 0.0000\n",
      "Evaluated 28600 books, current mean precision: 0.0000\n",
      "Evaluated 28700 books, current mean precision: 0.0000\n",
      "Evaluated 28800 books, current mean precision: 0.0000\n",
      "Evaluated 28900 books, current mean precision: 0.0000\n",
      "Evaluated 29000 books, current mean precision: 0.0000\n",
      "Evaluated 29100 books, current mean precision: 0.0000\n",
      "Evaluated 29200 books, current mean precision: 0.0000\n",
      "Evaluated 29300 books, current mean precision: 0.0000\n",
      "Evaluated 29400 books, current mean precision: 0.0000\n",
      "Evaluated 29500 books, current mean precision: 0.0000\n",
      "Evaluated 29600 books, current mean precision: 0.0000\n",
      "Evaluated 29700 books, current mean precision: 0.0000\n",
      "Evaluated 29800 books, current mean precision: 0.0000\n",
      "Evaluated 29900 books, current mean precision: 0.0000\n",
      "Evaluated 30000 books, current mean precision: 0.0000\n",
      "Evaluated 30100 books, current mean precision: 0.0000\n",
      "Evaluated 30200 books, current mean precision: 0.0000\n",
      "Evaluated 30300 books, current mean precision: 0.0000\n",
      "Evaluated 30400 books, current mean precision: 0.0000\n",
      "Evaluated 30500 books, current mean precision: 0.0000\n",
      "Evaluated 30600 books, current mean precision: 0.0000\n",
      "Evaluated 30700 books, current mean precision: 0.0000\n",
      "Evaluated 30800 books, current mean precision: 0.0000\n",
      "Evaluated 30900 books, current mean precision: 0.0000\n",
      "Evaluated 31000 books, current mean precision: 0.0000\n",
      "Evaluated 31100 books, current mean precision: 0.0000\n",
      "Evaluated 31200 books, current mean precision: 0.0000\n",
      "Evaluated 31300 books, current mean precision: 0.0000\n",
      "Evaluated 31400 books, current mean precision: 0.0000\n",
      "Evaluated 31500 books, current mean precision: 0.0000\n",
      "Evaluated 31600 books, current mean precision: 0.0000\n",
      "Evaluated 31700 books, current mean precision: 0.0000\n",
      "Evaluated 31800 books, current mean precision: 0.0000\n",
      "Evaluated 31900 books, current mean precision: 0.0000\n",
      "Evaluated 32000 books, current mean precision: 0.0000\n",
      "Evaluated 32100 books, current mean precision: 0.0000\n",
      "Evaluated 32200 books, current mean precision: 0.0000\n",
      "Evaluated 32300 books, current mean precision: 0.0000\n",
      "Evaluated 32400 books, current mean precision: 0.0000\n",
      "Evaluated 32500 books, current mean precision: 0.0000\n",
      "Evaluated 32600 books, current mean precision: 0.0000\n",
      "Evaluated 32700 books, current mean precision: 0.0000\n",
      "Evaluated 32800 books, current mean precision: 0.0000\n",
      "Evaluated 32900 books, current mean precision: 0.0000\n",
      "Evaluated 33000 books, current mean precision: 0.0000\n",
      "Evaluated 33100 books, current mean precision: 0.0000\n",
      "Evaluated 33200 books, current mean precision: 0.0000\n",
      "Evaluated 33300 books, current mean precision: 0.0000\n",
      "Evaluated 33400 books, current mean precision: 0.0000\n",
      "Evaluated 33500 books, current mean precision: 0.0000\n",
      "Evaluated 33600 books, current mean precision: 0.0000\n",
      "Evaluated 33700 books, current mean precision: 0.0000\n",
      "Evaluated 33800 books, current mean precision: 0.0000\n",
      "Evaluated 33900 books, current mean precision: 0.0000\n",
      "Evaluated 34000 books, current mean precision: 0.0000\n",
      "Evaluated 34100 books, current mean precision: 0.0000\n",
      "Evaluated 34200 books, current mean precision: 0.0000\n",
      "Evaluated 34300 books, current mean precision: 0.0000\n",
      "Evaluated 34400 books, current mean precision: 0.0000\n",
      "Evaluated 34500 books, current mean precision: 0.0000\n",
      "Evaluated 34600 books, current mean precision: 0.0000\n",
      "Evaluated 34700 books, current mean precision: 0.0000\n",
      "Evaluated 34800 books, current mean precision: 0.0000\n",
      "Evaluated 34900 books, current mean precision: 0.0000\n",
      "Evaluated 35000 books, current mean precision: 0.0000\n",
      "Evaluated 35100 books, current mean precision: 0.0000\n",
      "Evaluated 35200 books, current mean precision: 0.0000\n",
      "\n",
      "Evaluation complete!\n",
      "Mean Precision@10: 0.0000\n",
      "Number of books evaluated: 35222\n",
      "Precision distribution: min=0.0000, max=0.0000, std=0.0000\n",
      "\n",
      "Precision@10 for 'zap!_i'm_a_mind_reader': 0.0000\n",
      "Recommendations:\n",
      "        book_id                                              title  \\\n",
      "12687     74412                                      agnes_cecilia   \n",
      "18781   2036648                                        cliffhanger   \n",
      "7782    1676936                                     the_tin_forest   \n",
      "34782   1880695              pizza_pat_(step-into-reading,_step_2)   \n",
      "14960  10182327                                      i_am_the_book   \n",
      "30556   1059133  trixie_belden_and_the_gatehouse_mystery_(trixi...   \n",
      "888      132539       snowbound_mystery_(the_boxcar_children,_#13)   \n",
      "23183    183106           the_gatehouse_mystery_(trixie_belden_#3)   \n",
      "30515   9741560          the_gatehouse_mystery_(trixie_belden,_#3)   \n",
      "32751  20498877            trixie_belden_and_the_gatehouse_mystery   \n",
      "\n",
      "       similarity_score  \n",
      "12687          0.502813  \n",
      "18781          0.367469  \n",
      "7782           0.359076  \n",
      "34782          0.359076  \n",
      "14960          0.359076  \n",
      "30556          0.349893  \n",
      "888            0.349893  \n",
      "23183          0.349893  \n",
      "30515          0.349893  \n",
      "32751          0.349893  \n",
      "\n",
      "Ground truth similar_books: {'4082037', '834495', '7264857', '293722', '265923', '632537', '498957', '577769', '210311', '956602', '243424', '19435', '8036433', '632544', '570401', '46196', '11822984', '6265092'}\n",
      "Recommended book_ids: {np.int64(183106), np.int64(1880695), np.int64(2036648), np.int64(1676936), np.int64(74412), np.int64(10182327), np.int64(9741560), np.int64(132539), np.int64(1059133), np.int64(20498877)}\n",
      "Intersection (correct matches): set()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_books_data.xls')\n",
    "    print(f\"Dataset loaded successfully, rows: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cleaned_books_data.xls' not found, please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['book_id', 'title', 'description', 'similar_books']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    print(f\"Error: Dataset missing columns: {[col for col in required_columns if col not in df.columns]}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess dataset\n",
    "df = df[required_columns].drop_duplicates(subset=['book_id']).dropna(subset=['title', 'description'])\n",
    "print(f\"Rows after preprocessing: {len(df)}\")\n",
    "\n",
    "# Parse similar_books\n",
    "def parse_similar_books(similar_books):\n",
    "    try:\n",
    "        if isinstance(similar_books, str):\n",
    "            return ast.literal_eval(similar_books)\n",
    "        return similar_books\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "df['similar_books'] = df['similar_books'].apply(parse_similar_books)\n",
    "df = df[df['similar_books'].apply(len) > 0]\n",
    "print(f\"Rows with valid similar_books: {len(df)}\")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Combine title and description\n",
    "df['content'] = df['title'] + ' ' + df['description']\n",
    "print(f\"Content column sample: {df['content'].head(2)}\")\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=500, min_df=5)\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"TF-IDF matrix memory usage: {tfidf_matrix.data.nbytes / 1e6:.2f} MB\")\n",
    "\n",
    "# Nearest Neighbors model\n",
    "nn = NearestNeighbors(n_neighbors=11, metric='cosine', algorithm='brute', n_jobs=-1)\n",
    "nn.fit(tfidf_matrix)\n",
    "print(\"NearestNeighbors model fitted successfully\")\n",
    "\n",
    "# Mappings\n",
    "indices = pd.Series(df.index, index=df['title']).drop_duplicates(keep='first')\n",
    "book_id_to_index = pd.Series(df.index, index=df['book_id']).drop_duplicates(keep='first')\n",
    "index_to_book_id = pd.Series(df['book_id'].values, index=df.index)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_books(title, nn_model=nn, top_n=10):\n",
    "    if title not in indices:\n",
    "        return None, None\n",
    "    idx = indices[title]\n",
    "    if isinstance(idx, (int, np.integer)):\n",
    "        idx = idx\n",
    "    else:\n",
    "        idx = idx.iloc[0]\n",
    "    distances, book_indices = nn_model.kneighbors(tfidf_matrix[idx], n_neighbors=top_n + 1)\n",
    "    book_indices = book_indices.flatten()[1:]  # Exclude self\n",
    "    recommended_book_ids = index_to_book_id.iloc[book_indices].values\n",
    "    result = df.iloc[book_indices][['book_id', 'title', 'description']].copy()\n",
    "    result['similarity_score'] = 1 - distances.flatten()[1:]\n",
    "    return result, recommended_book_ids\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_recommendations(df, nn_model, top_n=10):\n",
    "    precisions = []\n",
    "    for idx, row in df.iterrows():\n",
    "        title = row['title']\n",
    "        ground_truth = set(row['similar_books'])\n",
    "        recommendations, recommended_book_ids = recommend_books(title, nn_model, top_n)\n",
    "        if recommendations is None:\n",
    "            continue\n",
    "        recommended_set = set(recommended_book_ids)\n",
    "        intersection = recommended_set.intersection(ground_truth)\n",
    "        precision = len(intersection) / top_n if top_n > 0 else 0\n",
    "        precisions.append(precision)\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Evaluated {idx + 1} books, current mean precision: {np.mean(precisions):.4f}\")\n",
    "    mean_precision = np.mean(precisions) if precisions else 0\n",
    "    return mean_precision, precisions\n",
    "\n",
    "# Function to calculate precision@K for a specific book\n",
    "def precision_at_k(title, df, nn_model, k=10):\n",
    "    recommendations, recommended_book_ids = recommend_books(title, nn_model, top_n=k)\n",
    "    if recommendations is None:\n",
    "        print(f\"Title '{title}' not found in the dataset.\")\n",
    "        return None\n",
    "    idx = indices[title]\n",
    "    ground_truth = set(df.loc[idx, 'similar_books'])\n",
    "    recommended_set = set(recommended_book_ids)\n",
    "    intersection = recommended_set.intersection(ground_truth)\n",
    "    precision = len(intersection) / k\n",
    "    return precision, intersection, ground_truth, recommended_set, recommendations\n",
    "\n",
    "# Run evaluation on entire dataset\n",
    "mean_precision, precisions = evaluate_recommendations(df, nn, top_n=10)\n",
    "print(f\"\\nEvaluation complete!\")\n",
    "print(f\"Mean Precision@10: {mean_precision:.4f}\")\n",
    "print(f\"Number of books evaluated: {len(precisions)}\")\n",
    "print(f\"Precision distribution: min={np.min(precisions):.4f}, max={np.max(precisions):.4f}, std={np.std(precisions):.4f}\")\n",
    "\n",
    "# Evaluate one specific book\n",
    "title = \"zap!_i'm_a_mind_reader\"\n",
    "result = precision_at_k(title, df, nn, k=10)\n",
    "if result:\n",
    "    precision, intersection, ground_truth, recommended_set, recommendations = result\n",
    "    print(f\"\\nPrecision@10 for '{title}': {precision:.4f}\")\n",
    "    print(\"Recommendations:\")\n",
    "    print(recommendations[['book_id', 'title', 'similarity_score']])\n",
    "    print(f\"\\nGround truth similar_books: {ground_truth}\")\n",
    "    print(f\"Recommended book_ids: {recommended_set}\")\n",
    "    print(f\"Intersection (correct matches): {intersection}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
